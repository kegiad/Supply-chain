# Supply-chain

## Description
This project uses large language models (LLMs) to optimize supply chain management by predicting inventory needs and prioritizing critical items for restocking based on external events.

## Features
- Predicts supply chain bottlenecks using AI.
- Prioritizes critical supplies.
- Integrates with external APIs for real-time data updates.

## Prerequisite
- Basic understanding of Large Language Models (LLMs): Familiarity with how LLMs like Meta Llama 3.2 work, including concepts like text generation, embeddings, and tokenization.
- Programming skills: Knowledge of Python and SQL.
- Basic understanding of how APIs work.

## Installation
- Ollama.
- The LLM used in this project is LLaMA 3.2 with 1B parameters.
- Download the model locally using Ollama if system requirements are satisfied.

## LLM used
- This project uses LLaMA 3.2 with 1B parameters.
- The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.
- Context length : 128K tokens 
